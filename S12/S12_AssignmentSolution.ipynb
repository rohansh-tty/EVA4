{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S12 AssignmentSolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NvTPKh6c1k3Un084peaAoHgkVtCGotvI",
      "authorship_tag": "ABX9TyNYEk+OsHenT/G9YjGTFnCJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f60825eb776347feba4fe42a9d6b9fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4586839f32146179f7977e1c4e4f9e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d082922ea10b4c33b33d345c60cac233",
              "IPY_MODEL_783e0a13cb3541e8acd94eab90d7597e"
            ]
          }
        },
        "c4586839f32146179f7977e1c4e4f9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d082922ea10b4c33b33d345c60cac233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8ee1a2ff75443b29dd757b0b78d6e68",
            "_dom_classes": [],
            "description": "Loading Train Folder: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c37351ba521e4ff6b7e2d83e3ccc7ed0"
          }
        },
        "783e0a13cb3541e8acd94eab90d7597e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b5dd151d0e1a490e9a8f78ae27859114",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [00:29&lt;00:00,  6.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bbdfd9004454995a1d0780b933f5096"
          }
        },
        "f8ee1a2ff75443b29dd757b0b78d6e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c37351ba521e4ff6b7e2d83e3ccc7ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5dd151d0e1a490e9a8f78ae27859114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bbdfd9004454995a1d0780b933f5096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec0a27a204154511919c577f4fe65577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb5eb3679abd4864ae17624234c25a2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df3ed5069fc347c0b081920cb1f6fa3e",
              "IPY_MODEL_558971ac9ef84008af00edc202eaad1b"
            ]
          }
        },
        "fb5eb3679abd4864ae17624234c25a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df3ed5069fc347c0b081920cb1f6fa3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2aa420526f7541619f65175924fa34b0",
            "_dom_classes": [],
            "description": "Loading Test Folder: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c96fc439be1944909676c61e26d52428"
          }
        },
        "558971ac9ef84008af00edc202eaad1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_156eed321b234150889b27876b81a786",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [00:53&lt;00:00, 187.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b4e0d58b9e8440ca452b30705c7b677"
          }
        },
        "2aa420526f7541619f65175924fa34b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c96fc439be1944909676c61e26d52428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "156eed321b234150889b27876b81a786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b4e0d58b9e8440ca452b30705c7b677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gilf641/EVA4/blob/master/S12/S12_AssignmentSolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTUngvjG4RIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "030490bf-becc-4729-cae0-9e9a0f5a2bcb"
      },
      "source": [
        "from __future__ import print_function\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PIV9QYf4RpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "07b62b61-8fdc-4a15-8bc9-5f09d24d0a84"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/EVA4/updLib2/evaLibrary\")\n",
        "!ls '/content/drive/My Drive/EVA4/updLib2/evaLibrary'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlbTestTransforms.py   cyclicLR.py     K-MeansClusteringCalculation.xlsx\n",
            "AlbTrainTransforms.py  DataLoaders.py  LR_Finder.py\n",
            "albumentations.py      displayData.py  __pycache__\n",
            "all.py\t\t       execute.py      resNet.py\n",
            "customNet.py\t       Gradcam.py      rohan_library.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2JvB5lj4hOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f484ee81-92db-40f3-b4da-e4d19b729ddf"
      },
      "source": [
        "\n",
        "import execute\n",
        "from resNet import ResNet18\n",
        "import displayData as display\n",
        "import Gradcam as gdc\n",
        "import albumentations as alb\n",
        "import DataLoaders as loader\n",
        "# import AlbTestTransforms\n",
        "# import AlbTrainTransforms\n",
        "import LR_Finder as lrf\n",
        "import cyclicLR as clr\n",
        "# import customNet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:LR_Finder:To enable mixed precision training, please install `apex`. Or you can re-install this package by the following command:\n",
            "  pip install torch-lr-finder -v --global-option=\"amp\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH8jRTuDwS8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "7b64de70-e0cd-4073-fc92-b0f84ac524ac"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-26 07:29:12--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip.5’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  20.0MB/s    in 14s     \n",
            "\n",
            "2020-06-26 07:29:27 (16.3 MB/s) - ‘tiny-imagenet-200.zip.5’ saved [248100043/248100043]\n",
            "\n",
            "replace tiny-imagenet-200/words.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "test  train  val  wnids.txt  words.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq-Cj8cMwWjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import notebook\n",
        "import zipfile\n",
        "import requests\n",
        "from io import StringIO,BytesIO\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------------------------------Main Function which calls everything--------------------------------------------------------------\n",
        "def TinyImageNetDataSet(splitRatio = 70,test_transforms = None,train_transforms = None):\n",
        "\n",
        "  # down_url  = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
        "  # download_images(down_url)\n",
        "  classes = class_names(url = \"tiny-imagenet-200/wnids.txt\")\n",
        "  dataset = TinyImageNet(classes,url=\"tiny-imagenet-200\")\n",
        "  train_len = len(dataset)*splitRatio//100\n",
        "  test_len = len(dataset) - train_len \n",
        "  train_set, val_set = random_split(dataset, [train_len, test_len])\n",
        "  train_dataset = DatasetFromSubset(train_set, transform=train_transforms)\n",
        "  test_dataset = DatasetFromSubset(val_set, transform=test_transforms)\n",
        "\n",
        "  return train_dataset, test_dataset,classes\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------Custom data set-------------------------------------------------------------------------\n",
        "\n",
        "class TinyImageNet(Dataset):\n",
        "    def __init__(self,classes,url):\n",
        "        self.data = []\n",
        "        self.target = []\n",
        "        self.classes = classes\n",
        "        self.url = url\n",
        "        \n",
        "        wnids = open(f\"{url}/wnids.txt\", \"r\")\n",
        "        \n",
        "        for wclass in notebook.tqdm(wnids,desc='Loading Train Folder', total = 200):\n",
        "          wclass = wclass.strip()\n",
        "          for i in os.listdir(url+'/train/'+wclass+'/images/'):\n",
        "            img = Image.open(url+\"/train/\"+wclass+\"/images/\"+i)\n",
        "            npimg = np.asarray(img)\n",
        "            \n",
        "            if(len(npimg.shape) ==2):\n",
        "             \n",
        "               npimg = np.repeat(npimg[:, :, np.newaxis], 3, axis=2)\n",
        "            self.data.append(npimg)  \n",
        "            self.target.append(self.classes.index(wclass))\n",
        "\n",
        "        val_file = open(f\"{url}/val/val_annotations.txt\", \"r\")\n",
        "        for i in notebook.tqdm(val_file,desc='Loading Test Folder',total =10000 ):\n",
        "          split_img, split_class = i.strip().split(\"\\t\")[:2]\n",
        "          img = Image.open(f\"{url}/val/images/{split_img}\")\n",
        "          npimg = np.asarray(img)\n",
        "          if(len(npimg.shape) ==2):\n",
        "                    \n",
        "                npimg = np.repeat(npimg[:, :, np.newaxis], 3, axis=2)\n",
        "          self.data.append(npimg)  \n",
        "          self.target.append(self.classes.index(split_class))\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data[idx]\n",
        "        target = self.target[idx]\n",
        "        img = data     \n",
        "        return data,target\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------Data subset which comes after splitting--------------------------------------------------\n",
        "\n",
        "class DatasetFromSubset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def class_names(url = \"tiny-imagenet-200/wnids.txt\"):\n",
        "  f = open(url, \"r\")\n",
        "  classes = []\n",
        "  for line in f:\n",
        "    classes.append(line.strip())\n",
        "  return classes\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfWkLT0XwgTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "import albumentations.pytorch as AP\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class AlbumentationTransforms:\n",
        "  \"\"\"\n",
        "  Helper class to create test and train transforms using Albumentations\n",
        "  \"\"\"\n",
        "  def __init__(self, transforms_list=[]):\n",
        "    transforms_list.append(AP.ToTensor())\n",
        "\n",
        "    self.transforms = A.Compose(transforms_list)\n",
        "\n",
        "\n",
        "  def __call__(self, img):\n",
        "    img = np.array(img)\n",
        "    return self.transforms(image=img)['image']\n",
        "\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgTuGfXbwpNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "\n",
        "\n",
        "def convData_To_Dataloader(trainset,testset,seed=1,batch_size=128,num_workers=4,pin_memory=True):\n",
        "\n",
        "\tSEED = 1\n",
        "\n",
        "\t# CUDA?\n",
        "\tcuda = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "\t# For reproducibility\n",
        "\ttorch.manual_seed(SEED)\n",
        "\n",
        "\tif cuda:\n",
        "\t\t\ttorch.cuda.manual_seed(SEED)\n",
        "\n",
        "\tdataloader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "\ttrainloader = torch.utils.data.DataLoader(trainset, **dataloader_args)\n",
        "\ttestloader = torch.utils.data.DataLoader(testset, **dataloader_args)\n",
        "\n",
        "\n",
        "\treturn  trainloader, testloader\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9YMQMPZws3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "f60825eb776347feba4fe42a9d6b9fff",
            "c4586839f32146179f7977e1c4e4f9e8",
            "d082922ea10b4c33b33d345c60cac233",
            "783e0a13cb3541e8acd94eab90d7597e",
            "f8ee1a2ff75443b29dd757b0b78d6e68",
            "c37351ba521e4ff6b7e2d83e3ccc7ed0",
            "b5dd151d0e1a490e9a8f78ae27859114",
            "6bbdfd9004454995a1d0780b933f5096",
            "ec0a27a204154511919c577f4fe65577",
            "fb5eb3679abd4864ae17624234c25a2f",
            "df3ed5069fc347c0b081920cb1f6fa3e",
            "558971ac9ef84008af00edc202eaad1b",
            "2aa420526f7541619f65175924fa34b0",
            "c96fc439be1944909676c61e26d52428",
            "156eed321b234150889b27876b81a786",
            "5b4e0d58b9e8440ca452b30705c7b677"
          ]
        },
        "outputId": "fd02b439-afc7-4d08-bea3-09a6abdf904f"
      },
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "channel_means = (0.442,0.442,0.442)\n",
        "channel_stdevs = (0.278, 0.278, 0.278)\n",
        "train_transform = AlbumentationTransforms([       \n",
        "                                        A.Flip(p=0.5),\n",
        "                                        A.Cutout(num_holes = 2, max_h_size = 8, max_w_size = 8, p = 1.0),\n",
        "                                        A.Normalize(mean=channel_means, std=channel_stdevs)   \n",
        "                                       ])\n",
        "test_transform = AlbumentationTransforms([A.Normalize(mean=channel_means, std=channel_stdevs)])\n",
        "train_dataset , test_dataset,classes = TinyImageNetDataSet(splitRatio = 70,test_transforms = test_transform,train_transforms = train_transform)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f60825eb776347feba4fe42a9d6b9fff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Loading Train Folder', max=200.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec0a27a204154511919c577f4fe65577",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Loading Test Folder', max=10000.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXMsx2luw6Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLoader, testLoader = convData_To_Dataloader(train_dataset,test_dataset,batch_size=128)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL0IqoL0xyJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential() # if no change in number of channels then self.shortcut is like empty\n",
        "        if stride != 1 or in_planes != self.expansion*planes: # this is like if there's change in channel number only then it's used I guess\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# This commenting is for ResNet18\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=200): # block = BasicBlock, num_blocks = [2,2,2,2]\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64  # maybe this is the number of kernels at the start\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False) # conv2 with incoming 3 channels\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzn2pxR4x0EH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7a1b512-e6eb-433f-d650-c6b5843293fc"
      },
      "source": [
        "from torchsummary import summary\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "model = ResNet18().to(device)\n",
        "summary(model, input_size=(3, 64, 64))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "            Conv2d-3           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 64, 64]             128\n",
            "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "        BasicBlock-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
            "           Conv2d-10           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 64, 64]             128\n",
            "       BasicBlock-12           [-1, 64, 64, 64]               0\n",
            "           Conv2d-13          [-1, 128, 32, 32]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 32, 32]             256\n",
            "           Conv2d-15          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 32, 32]             256\n",
            "           Conv2d-17          [-1, 128, 32, 32]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 32, 32]             256\n",
            "       BasicBlock-19          [-1, 128, 32, 32]               0\n",
            "           Conv2d-20          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 32, 32]             256\n",
            "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
            "       BasicBlock-24          [-1, 128, 32, 32]               0\n",
            "           Conv2d-25          [-1, 256, 16, 16]         294,912\n",
            "      BatchNorm2d-26          [-1, 256, 16, 16]             512\n",
            "           Conv2d-27          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-28          [-1, 256, 16, 16]             512\n",
            "           Conv2d-29          [-1, 256, 16, 16]          32,768\n",
            "      BatchNorm2d-30          [-1, 256, 16, 16]             512\n",
            "       BasicBlock-31          [-1, 256, 16, 16]               0\n",
            "           Conv2d-32          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-33          [-1, 256, 16, 16]             512\n",
            "           Conv2d-34          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-35          [-1, 256, 16, 16]             512\n",
            "       BasicBlock-36          [-1, 256, 16, 16]               0\n",
            "           Conv2d-37            [-1, 512, 8, 8]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-39            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-41            [-1, 512, 8, 8]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 8, 8]           1,024\n",
            "       BasicBlock-43            [-1, 512, 8, 8]               0\n",
            "           Conv2d-44            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-46            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 8, 8]           1,024\n",
            "       BasicBlock-48            [-1, 512, 8, 8]               0\n",
            "           Linear-49                  [-1, 200]         102,600\n",
            "================================================================\n",
            "Total params: 11,271,432\n",
            "Trainable params: 11,271,432\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 45.00\n",
            "Params size (MB): 43.00\n",
            "Estimated Total Size (MB): 88.05\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp7hLo0W1pvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUCfFNcdx19-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torch.optim as optim\n",
        "# import torch.nn as nn\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
        "\n",
        "# lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "# lr_finder.range_test(trainLoader, end_lr=100, num_iter=100, step_mode='exp')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eafewx_S3zAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lr_finder.plot()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6eIxLyN4A46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lr_finder.reset()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEPl3Uwm4FXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clr.lr_rangetest(device, model, trainLoader, criterion, 0.001, 0.01, 30)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdMC79dj7AGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "fdb297fc-4e46-4bc4-8cc3-2ad82bdf388e"
      },
      "source": [
        "incorrectSamples = []\n",
        "correctSamples = []\n",
        "correctLabels = []\n",
        "learningRates = []\n",
        "model = ResNet18().to(device)\n",
        "EPOCHS = 24\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.95, weight_decay = 1e-2, nesterov = True) \n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 0.02, total_steps=15000, epochs = 24, steps_per_epoch=len(trainLoader),\n",
        "                                                pct_start=1/3, anneal_strategy='linear', cycle_momentum=True, \n",
        "                                                base_momentum=0.85, max_momentum=0.95, div_factor=10, final_div_factor=1)\n",
        "\n",
        "\n",
        "model1 = execute.Test_Train(model, device, optimizer, scheduler, criterion)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  print('EPOCH: ',epoch)\n",
        "  model1.train(trainLoader, epoch, L1lambda=1e-5)\n",
        "  model1.test(testLoader, 'model1.pt', correctSamples, correctLabels, incorrectSamples)\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print('Learning Rate = {a} for EPOCH {e}'.format(a = round(param_group['lr'],5), e=epoch+1))\n",
        "    learningRates.append(param_group['lr'])\n",
        "  scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=4.756042003631592 Batch_id=601 Accuracy=7.41: 100%|██████████| 602/602 [07:27<00:00,  1.34it/s]\n",
            "  0%|          | 0/602 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss has  decreased (inf --> 4.2313).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 4.2313, Accuracy: 3295/33000 (9.98%)\n",
            "\n",
            "Learning Rate = 0.00417 for EPOCH 2\n",
            "EPOCH:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=4.339092254638672 Batch_id=440 Accuracy=14.52:  73%|███████▎  | 441/602 [05:28<01:59,  1.35it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni2O-eOA7RFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = []\n",
        "# while(1):\n",
        "#   a.append(\"b\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}